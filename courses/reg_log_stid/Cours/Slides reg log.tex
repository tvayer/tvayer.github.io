
\documentclass[9pt, xcolor=table]{beamer}

\usepackage[ansinew]{inputenc}
\usepackage[cyr]{aeguill}
\usepackage{xspace}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[francais]{babel}
\usepackage{pgfpages}
\usepackage{graphicx}
\usepackage{array}
%\usepackage{subcaption}
%\usepackage{booktabs}
\usepackage{multirow}

\definecolor{grisclair}{gray}{0.8}


		\def\Var{{\mathbb{V}\rm ar}\,}
		\def\E{{\mathbb{E}}\,}
		\def\Cov{{\mathbb{C}\rm ov}\,}
		\def\Corr{{\mathbb{C}\rm orr}\,}
				\def\Prob{{\mathbb{P}}\,}
		
		

%%============================================================================================
%to print : 4 pages on 1 + option trans in documentclass
%\pgfpagesuselayout{4 on 1}[a4paper, landscape,border shrink = 5mm]
%\newenvironment{myframe}{\begin{frame}\frametitle{\insertsectionhead}\framesubtitle{\vskip10pt\large\insertsubsectionhead}}{\end{frame}\note{ ~~ }}

%%============================================================================================
% pour projeter

\newenvironment{myframe}{\begin{frame}\frametitle{\insertsectionhead}\framesubtitle{\vskip10pt\large\insertsubsectionhead}}{\end{frame}}

%%============================================================================================

\setbeameroption{show notes}
\setbeamertemplate{note page}[default]


%\pgfdeclareimage[height=0.575cm]{frameStid}{logoSTID.jpg}

%define theme color
\definecolor{blueStid}{RGB}{16,16,156}

\setbeamercolor{structure}{fg=blueStid, bg=white}
\setbeamercolor{alert}{fg=red, bg=white}
\definecolor{vert}{RGB}{0,153,0}


%\usetheme{boxes}

%headline:navigation bar
%\useoutertheme[subsection=false]{smoothbars}

%define the block theme appearance
\definecolor{yellowStid}{RGB}{255,204,0}
\setbeamercolor*{block title}{fg=yellowStid,bg=blueStid}
\setbeamercolor*{block body}{fg=normal text.fg,bg=blueStid!20}


%footline: stid logo
%\setbeamertemplate{footline}
%{\leavevmode
%\begin{beamercolorbox}[width=1\paperwidth]{section in head/foot}
%\pgfuseimage{frameStid}
%\end{beamercolorbox}%
%}

%insert the number of pages at the bottom rigth
\logo{\insertframenumber/\inserttotalframenumber}

%the items are circle
\setbeamertemplate{itemize items}[circle]

%new environment in order to avoid to rewrite the frametitle at each slides...
%\newenvironment{myframe}{\begin{frame}[fragile,environment=myframe]  \frametitle{\vskip5pt \insertsectionhead \vskip1pt \small\insertsubsectionhead }}{\end{frame}}

%\newenvironment{myframe}{\begin{frame}\frametitle{\insertsectionhead}\framesubtitle{\vskip10pt\large\insertsubsectionhead}}{\end{frame}}


% print the outline at each modification of frame
\AtBeginSection[] 
{
\begin{frame}<beamer>
\frametitle{Sommaire}
\small \tableofcontents[currentsection, hideothersubsections]
\end{frame}
}

\usepackage{tikz}
\usetikzlibrary{calc,matrix,decorations.markings,decorations.pathreplacing, backgrounds}
\usetikzlibrary{arrows,positioning} 

\tikzset{
    %Define standard arrow tip
    >=stealth',
    %Define style for boxes
    punkt/.style={
           rectangle,
           rounded corners,
           draw=black,  thick,
           text width=16em,
           minimum height=2em,
           text centered},
    % Define arrow style
    pil/.style={
           ->,
           thick,
           shorten <=2pt,
           shorten >=2pt,}
					    invisible/.style={opacity=0},
    visible on/.style={alt=#1{}{invisible}},
    alt/.code args={<#1>#2#3}{%
      \alt<#1>{\pgfkeysalso{#2}}{\pgfkeysalso{#3}} % \pgfkeysalso doesn't change the path
    },
}


\definecolor{colone}{RGB}{209,220,204}
\definecolor{colfive}{RGB}{245,238,197}

\tikzset{ 
  table/.style={
    matrix of nodes,
    row sep=-\pgflinewidth,
    column sep=-\pgflinewidth,
    nodes={rectangle,text width=1.7cm,align=center},
    text depth=1.25ex,
    text height=2.5ex,
    nodes in empty cells
  }
}

%\renewcommand*{\familydefault}{\sfdefault}
\newcommand{\cbox}[1]{\parbox[t]{1.6cm}{\centering #1}}
\newcommand{\vect}[1]{\boldsymbol{#1}}	

%title page informations
\title{Régression logistique\\ \textcolor{vert}{[Logistic regression]}}
\author{Titouan Vayer,Laetitia Chapel}
\institute{\includegraphics[width=0.3\textwidth]{logoSTID.jpg}\\ \scriptsize{STID 2}}
\date{2019 -- 2020} 
 


%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\begin{document}

%============================================================================================ new section
\frame[plain]{\titlepage} 
%\note[itemize]{
%\item who I am
%\item rappel de l'emploi du temps
%\item évaluation
%}


%============================================================================================ new section
\begin{frame}
\frametitle{Sommaire}
\small \tableofcontents[hideothersubsections]
\end{frame}

%============================================================================================ new section
\section{Introduction : la classification supervisée binaire}

%------------ new frame
\begin{myframe}
\structure{Organisation du cours}
\begin{itemize}
  \item 2 CMs
  \item 6 TDs: papier \& ordinateur
  \item Evaluation sur table papier crayon 1h30 avec anti-sèche autorisé 
\end{itemize}
\end{myframe}

\begin{myframe}
\begin{block}{Objectif de la classification supervisée binaire}
Apprendre à un ordinateur \textbf{à classer} selon \textbf{deux catégories} des individus $x$ en fonction de leurs \textbf{données descriptives} $(x_{1},...,x_{p})$ 

\end{block}

\begin{center}
\includegraphics[width=.7\linewidth]{fig/datax.png}
\end{center}

\pause

Par exemple:
\begin{itemize}
\item Donner un crédit en fonction de données d'un individu (âge,csp,...)
\item Détecter une maladie en fonction de données d'une image
\item Proposer un médicament adapté en fonction des données médicales d'un individu
\item Détecter un obstacle pour la voiture autonome
\item Trier des CVs
\end{itemize}

\end{myframe}

\begin{myframe}
\vspace{-5mm}

     \begin{block}{Comment apprendre $f$ ?}
         \begin{itemize}
             \item Généralement on dispose d'un ensemble de plusieurs individus ("un dataset"), de leurs données descriptives et de leur catégorie respective ("la classe de l'individu")
             \item On essaye d'apprendre une "règle" de classification qui sépare nos données selon les deux catégories
             \item La règle est une fonction $f$ qui s'appelle un classifeur 
         \end{itemize}
     \end{block}


\end{myframe}


\begin{myframe}
\vspace{-5mm}

     \begin{block}{Comment apprendre $f$ ?}
         \begin{itemize}
             \item Généralement on dispose d'un ensemble de plusieurs individus ("un dataset"), de leurs données descriptives et de leur catégorie respective ("la classe de l'individu")
             \item On essaye d'apprendre une "règle" de classification qui sépare nos données selon les deux catégories
             \item La règle est une fonction $f$ qui s'appelle un classifeur 
         \end{itemize}
     \end{block}



    \begin{center}
       \only<1>{\includegraphics[width=.8\linewidth]{fig/2pixelcam}}
       \only<2>{\includegraphics[width=.8\linewidth]{fig/2pixelcam_labels}}
       \only<3>{\includegraphics[width=.8\linewidth]{fig/2pixelcam_classif}}
       \only<4>{\includegraphics[height=3.5cm]{fig/amazon.pdf}  \includegraphics[height=3cm]{fig/otda_prostate_all}\vspace{1cm} }
     \end{center}


\end{myframe}

\begin{myframe}

\begin{block}{La classification supervisée binaire}
L'objectif de la classification supervisée binaire est:

\begin{itemize}
\item Apprendre à un ordinateur (avec un algorithme codé dans un langage informatique comme R)
\item A trouver une règle de classification ($f$)
\item En fonction de données d'individus ($x$ et leur classe)
\item De sorte que la règle de décision satisfasse un certain critère (qu'elle classifie au mieux tous nos points)
\end{itemize}

\end{block}

\end{myframe}

\begin{myframe}
\begin{itemize}
	\item  \structure{Entrée} : un ensemble de $N$ points décrits par $p$ attributs, où $\left\{\vect{x}_{i}\right\}_{i=1\cdots p}$ contient les valeurs prises par la $i^{\text{ème}}$ variable pour l'ensemble des individus %$\left\{\vect{x}_{i}\right\}_{i=1\cdotsN} \in \mathcal{X}= \mathbb{R}^{p}$ , où chaque point $\vect{x}_{i}$ contient $p$ attributs   
	$ \vect{x}_{i} = 
	\begin{bmatrix} % or pmatrix or bmatrix or Bmatrix or ...
     x_{i}^1 \\
     x_{i}^2 \\
     \cdots \\
    x_{i}^N \\
   \end{bmatrix}$ et on note $\vect{x}^n$ les attributs du $n^{\text{ème}}$ individu $\vect{x}^n=[x_{1}^n, x_{2}^n, \cdots, x_{p}^n]$
\item Des classes $\vect{y} =  \begin{bmatrix} % or pmatrix or bmatrix or Bmatrix or ...
     y_{1} \\
     y_{2} \\
     \cdots \\
    y_{N} \\
   \end{bmatrix} \in \mathcal{Y}$, avec $y_n$ la classe du $n^{\text{ème}}$ individu
   \pause
   \item \structure{Apprentissage supervisé} : la sortie désirée est connue \\
\underline{But} : trouver une fonction $f$ telle que %$f : \mathcal{X} \rightarrow \mathcal{Y}$, 
$$f([\vect{x}_{1}, \vect{x}_{2}, \cdots, \vect{x}_{p}])+\boldsymbol{\epsilon} = \vect{y}$$.
\begin{itemize}
\item si $\mathcal{Y} = \mathbb{R}$ : problème de régression
\item si $\mathcal{Y} \in \mathcal{S}$, avec $\mathcal{S}$ un ensemble fini : problème de classification
\item si $\mathcal{S}=\{0,1\}$ contient 2 éléments : classification binaire
	\end{itemize}
	
\end{itemize} 
\end{myframe}



%============================================================================================ new section
\section{Objectifs du cours}
\begin{myframe}
\begin{itemize}
	\item Comprendre le principe de la régression logistique
	\item Etre capable de mettre en oeuvre une régression logistique avec R
	\item Savoir construire un modèle de régression logistique
	\item Etre capable d'interpréter les résultats d'une régression logistique
\end{itemize}
\end{myframe}

%============================================================================================ new section
\section{Le modèle de régression logistique}
\subsection{Le modèle de régression linéaire}
\begin{myframe}
$$\vect{y} = f(\vect{X})+\boldsymbol{\epsilon} = \beta_0 + \beta_1\vect{x_1}+ \cdots + \beta_p\vect{x_p} + \boldsymbol{\epsilon} $$
et pour une observation $n$ : 
$$y_n = \beta_0 + \beta_1{x_{1}^n}+ \cdots + \beta_p{x_{p}^n} + \epsilon_n \in \mathbb{R}$$
\begin{itemize}
	\item Estimations $b_0, b_1, \cdots, b_p$  des coefficients du modèle $\beta_0, \beta_1, \cdots, \beta_p$ par la méthode des MC
	\item Test sur les coefficients
	\item Mesure de qualité du modèle
\end{itemize}
\end{myframe}

\subsection{Régression logistique}
\begin{myframe}
\begin{itemize}
	\item Modéliser $\vect{y}\in \{0,1\}$
	\only<1>{
	\begin{figure}
		\centering
			\includegraphics[width=0.70\textwidth]{fig/dataPoints.pdf}
		\label{fig:regheart}
	\end{figure}
	}
		\only<2>{
	\begin{figure}
		\centering
\includegraphics[width=0.70\textwidth]{fig/regheart.pdf}
		\label{fig:regheart}
	\end{figure}
	}
	\only<2>{\item Le modèle linéaire ne convient pas !}
\end{itemize}
\end{myframe}

\begin{myframe}
\begin{itemize}
\item Dans le cadre de la régression logistique on cherche à modéliser les probabilités:
$$\pi(\vect{x}^n) = \Prob(y_n = 1 \left|\right.  \vect{x}^n) \hbox{ ou } 1-\pi(\vect{x}^n) = \Prob(y_n = 0 \left|\right. \vect{x}^n)$$
et pour l'ensemble des individus
$$\pi(\vect{X}) = \Prob(\vect{y} = 1 \left|\right. \vect{X}) \hbox{ ou } 1-\pi(\vect{X}) = \Prob(\vect{y} = 0 \left|\right. \vect{X})$$
%... mais $\pi \in [0,1]$
	\begin{figure}
		\centering
			%\only<1>{\includegraphics[width=0.60\textwidth]{fig/pmaladieage.pdf}}
			\includegraphics[width=0.60\textwidth]{fig/ajustlogit.pdf}
		\label{fig:pmaladieage}
	\end{figure}
\item Une fois qu'on connait la probabilité qu'a un individu d'appartenir à une classe il est facile de deviner à quelle classe il appartient. 
\end{itemize}
\end{myframe}


\begin{myframe}

Comment modéliser $\pi(x^{n})$ ?

\begin{itemize}
\item La régression logistique est basée sur la fonction logistique
$$f(z) = \dfrac{\exp(z)}{1+\exp(z)} = \dfrac{1}{1+\exp(-z)} $$
avec $f(z) \in [0,1]$ et $z \in \mathbb{R}$
\begin{figure}
		\centering
			\includegraphics[width=0.60\textwidth]{fig/logfunction.pdf}
		\label{fig:pmaladieage}
	\end{figure}
\end{itemize}
\end{myframe}

\subsection{Le modèle}
\begin{myframe}
\begin{itemize}
\item Le modèle de régression logistique s'écrit :
$$\pi(\vect{X}) = \dfrac{\exp(\beta_0 + \beta_1\vect{x}_1+ \cdots + \beta_p\vect{x}_p)}{1+\exp(\beta_0 + \beta_1\vect{x}_1+ \cdots + \beta_p\vect{x}_p)} $$
avec $\pi(\vect{x}^n) \in [0,1]$ et $\beta_0 + \beta_1{x_{1}^n}+ \cdots + \beta_p{x_{p}^n} \in \mathbb{R}$
\item ou de façon équivalente: 
$$\text{logit}(\pi(\vect{X})) = \log\left(\dfrac{\pi(\vect{X})}{1-\pi(\vect{X})} \right)= \beta_0 + \beta_1\vect{x}_1+ \cdots + \beta_p\vect{x}_p $$
\item <2> avec ${\vect{x}_i}$ variables quantitatives ou binaires représentant les données des individus.
\end{itemize}
\end{myframe}

\subsection{Les variables explicatives}
\begin{myframe}
\begin{itemize}
\item \textbf{Variable explicative qualitative à 2 modalités} : les modalités sont recodées $x_{i}^n\in \{0,1\}$, la modalité $0$ étant appelée \textit{modalité de référence}.
\item \textbf{Variable explicative qualitative à $m>2$ modalités} : on créé $m-1$ \textit{variables design} (indicatrices associées à chaque modalité).
\item \textbf{Variable explicative quantitative} : on vérifie l'hypothèse de \textit{linéarité du logit}.
\end{itemize}
\end{myframe}
\subsection{Hypothèse de linéarité du logit}
\begin{myframe}
\begin{itemize}
\item Lorsqu'une variable passe de la valeur $x_1$ à $x_1+1$, la valeur $\text{logit}(\pi(x))$  augmente de $\beta_1$, quelle que soit la valeur de $x_1$ $\Rightarrow$ le logit est linéaire.
\item On doit vérifier cette hypothèse pour pouvoir intégrer une variable quantitative dans le modèle, et la mettre en classe sinon.
\item Pour vérifier l'hypothèse, on peut notamment mettre la variable en classe, puis tracer l'évolution en fonction du logit.
\end{itemize}
\end{myframe}


%============================================================================================ new section
\section{Estimation des paramètres du modèle}
\begin{myframe}



\begin{block}{Comment trouver les paramètre $\beta_{0},...,\beta_{p}$ ?}
L'objectif est de trouver $\beta_{0},...,\beta_{p}$ de sorte que notre modèle "colle" le mieux à nos données.

\end{block}

\pause

\begin{itemize}
\item On ne peut pas utiliser la méthode des moindres carrés (on ne modélise pas directement $y_n$) : lorsque $y_n \in \mathbb{R}$, on peut écrire
$$\min \sum_{n=1}^{N} e_n^2 = \min \sum_{n=1}^{N} (y_n-\hat{y}_n)^2 = \min \sum_{n=1}^{N} (y_n-(\beta_0 + \beta_1{x_{1}^n}+ \cdots + \beta_p{x_{p}^n}))^2$$
\item<2-> On utilise la méthode du maximum de vraisemblance
$$ \max \prod_{n=1}^{N} \pi(x^n)^{y_n}	 \times (1-\pi(x^n))^{1-y_n}$$
\begin{enumerate}
\item<3> si $y_n = 1$, on veut que $\pi(x^n)$ soit proche de 1 $\Rightarrow$ $\pi(x^n)^{y_n}$ proche de 1 et $(1-\pi(x^n))^{1-y_n}=1$
\item<3> si $y_n = 0$, on veut que $\pi(x^n)$ soit proche de 0 $\Rightarrow$  $\pi(x^n)^{y_n}=1$  et $(1-\pi(x^n))^{1-y_n}$ proche de 1
\end{enumerate}
\end{itemize}
\end{myframe}

\begin{myframe}
\begin{itemize}
\item On cherche donc des estimations $b_0, b_1, \cdots, b_p$ des paramètres inconnus $\beta_0, \beta_1, \cdots , \beta_p$ telles que la vraisemblance $\mathcal{L}$ soit maximimum : 
$$ \max \mathcal{L} = \max \prod_{n=1}^{N} \pi(x^n)^{y_n}	 \times (1-\pi(x^n))^{1-y_n}$$
avec $$\pi(x^n) = \dfrac{\exp(\beta_0 + \beta_1{x_{1}^n}+ \cdots + \beta_p{x_{p}^n})}{1+\exp(\beta_0 + \beta_1{x_{1}^n}+ \cdots + \beta_p{x_{p}^n})} $$
\item ce qui est équivalent à minimiser la déviance $ -2 \times \log(\mathcal{L})$
$$\min -2 \times \log(\mathcal{L})$$
\item<2-> On utilise des méthodes d'optimisation pour résoudre le problème
\item<3> \textit{Note} : pour $N$ fixé, le modèle 1 sera meilleur que le modèle 2 si $\mathcal{L}_1 > \mathcal{L}_2$
\end{itemize}
\end{myframe}

\subsection{Test du rapport de vraisemblance : test de significativité globale du modèle}
\begin{myframe}
\begin{itemize}
\item On cherche à savoir si il y a un ``lien'' entre au moins une variable explicative $\vect{x}_1$, $\vect{x}_2$, $\cdots$, $\vect{x}_p$ et la variable à expliquer $Y$
$$\mathcal{H}_0 : \beta_1 = \cdots = \beta_p=0 $$
$$\mathcal{H}_1 : \exists i \text{ tel que }\beta_i\neq0 $$
\item<2> Sous $\mathcal{H}_0$, 
$$D = -2 \log\left( \dfrac{\mathcal{L}_0}{\mathcal{L}_p} \right) \sim \chi^2_p$$
\end{itemize}
\end{myframe}

\subsection{Test de Wald : test de significativité individuelle des variables}
\begin{myframe}
\begin{itemize}
\item On teste la significativité individuelle d'une variable $\vect{x}_i$
$$\mathcal{H}_0 : \beta_i = 0 $$
$$\mathcal{H}_1 : \beta_i\neq0 $$
\item<2> Sous $\mathcal{H}_0$, 
$$W^{2} = \left( \dfrac{b_i^{2}}{\hat{VAR}(b_i)} \right) \sim \chi^2_1$$

where $\hat{VAR}(b_i)$ is an estimation of the variance of $b_i$
\end{itemize}
\end{myframe}

%============================================================================================ new section
\section{Odds et odds-ratio}
\begin{myframe}
\structure{odds}
\begin{itemize}
\item La régression logistique est basée sur l'estimation d'un \structure{odds} ou \structure{cote}
$$ \text{odds} = \dfrac{\Prob(y_n = 1 \left|\right.  \vect{x}^n)}{\Prob(y_n = 0 \left|\right.  \vect{x}^n)} = \dfrac{\pi(\vect{x}^n)}{1-\pi(\vect{x}^n)}$$
\begin{block}{Exemple}
En Bretagne, il y a 25\% de chances de pleuvoir demain. En Irlande, il y a 75 \% de chances de pleuvoir demain.\\
odds(Bretagne) ? odds(Irlande) ?
\end{block}
\end{itemize}
\end{myframe}

\begin{myframe}
\structure{Interprétation de $b_0$}
\begin{itemize}
\item Soit un modèle qui ne contient que l'intercept (pas de variable explicative)
$$\text{logit}(\pi(\vect{x}^n)) = \beta_0$$
\item Une estimation $b_0$ du paramètre inconnu $\beta_0$ correspond au logarithme de l'odds
$$b_0 = \log \dfrac{\pi(\vect{x}^n)}{1-\pi(\vect{x}^n)}$$
et on a donc
$$\exp(b_0) =  \dfrac{\pi(\vect{x}^n)}{1-\pi(\vect{x}^n)}$$
\item $\exp(b_0)$ correspond donc au nombre de fois de chances de plus que l'on a d'observer $y=1$ par rapport à $y=0$. 
\end{itemize}
\end{myframe}

\begin{myframe}
\structure{Odds-ratio : cas d'une variable explicative binaire $x \in \{0,1\}$}
\begin{itemize}
\item Odds-ratio : rapport entre 2 odds
\item Soit une variable $x$ qui prend 2 modalités : 0 ou 1
$$OR(x) = \dfrac{\pi(1)}{1-\pi(1)} /  \dfrac{\pi(0)}{1-\pi(0)}$$
\item Indique ainsi quelle est la quantité de chance en plus d'être $y=1$ dans le groupe $x=1$ par rapport au groupe $x = 0$. 
\begin{block}{Exemple}
En Bretagne, il y a 25\% de chances de pleuvoir demain. En Irlande, il y a 75 \% de chances de pleuvoir demain.\\
odds-ratio(Irlande vs Bretagne) ?
\end{block}
\end{itemize}
\end{myframe}


\begin{myframe}
\structure{Odds-ratio : cas d'une variable explicative binaire $x \in \{0,1\}$}
\begin{itemize}
\item Dans ce cas, on a (preuve...)
$$OR(x) = \exp(\beta_1)$$
\item Vocabulaire : 
\begin{itemize}
\item si OR > 1 : facteur de risque
\item si OR < 1 : facteur de protection
\end{itemize} 
\item On peut également calculer des IC autour des OR
\end{itemize}
\end{myframe}

\begin{myframe}
\structure{Odds-ratio : cas d'une variable explicative continue $x \in \mathbb{R}$}
\begin{itemize}
\item Dans ce cas, on a (preuve...)
$$OR(x) = \exp(\beta_1)$$
qui correspond à l'évolution de la chance d'être $y=1$ lorsque la variable $x$ augmente de 1 unité (passe de la valeur $a$ à la valeur $a+1$)
\item Attention à l'hypothèse de linéarité du logit !
\end{itemize}
\end{myframe}


%============================================================================================ new section
\section{Evaluation et sélection du ``meilleur'' modèle}
\begin{myframe}
\begin{itemize}
\item Approche traditionnelle : chercher le modèle le plus parsimonieux qui explique au mieux les données
\item Idée générale : on cherche le modèle qui maximise la vraisemblance. MAIS, la vraisemblance augmente avec la complexité du modèle : on cherche donc un compromis entre la qualité de l'ajustement et la complexité du modèle.
\item 2 critères classiques :
\begin{itemize}
\item Critère d'Akaike $$AIC = -2 \mathcal{L} + 2p$$
\item Critère Bayes Information Criterion $$BIC =  -2 \mathcal{L} + p \log(N)$$
 \end{itemize} 
\end{itemize}
\end{myframe}


\begin{myframe}
\structure{Méthodes de sélection}
\begin{itemize}
\item Il est coûteux voire impossible de tester tous les modèles et choisir celui qui minimise le critère BIC ou AIC : on préfère des méthodes pas à pas
\item Méthode ascendante : on ajoute à chaque itération une variable dans le modèle -- forward
\item Méthode descendante : on supprime à chaque itération une variable du modèle -- backward
\item Méthode stepwise

\end{itemize}
\end{myframe}

\begin{myframe}
\structure{Evaluation d'un modèle}
\begin{itemize}
\item On peut également comparer des modèles en fonction de leur performance en prédiction
\item parcours école : cf module introduction à l'apprentissage automatique (calcul de l'estimation du risque réel, de l'aire sous la courbe ROC, TVP, TVN)
\item parcours STID : cf module classification

\end{itemize}
\end{myframe}

%============================================================================================ new section
% \section{Et la suite ?}
% \begin{myframe}
% \begin{itemize}
% \item A t-on résolu le problème initial ? Quid de $\hat{y}$ ?

% \end{itemize}
% \end{myframe}

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\end{document}