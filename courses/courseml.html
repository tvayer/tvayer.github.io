<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="pandoc" />
  <title>Fundamentals of Machine Learning</title>
  <link rel="stylesheet" href="https://latex.now.sh/style.css">
  <link rel="stylesheet" href="prism/prism.css">
  <script src="prism/prism.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style type="text/css">
    body {
      counter-reset: fignumber sidenote-counter theorem definition;
    }
    div#back2index {text-align: right;}
    h1#toctitle {text-align: left;}
    #TOC ul {list-style-type: none;}
    h1:not(.title) {margin-top: 1.625rem;}
    img {display: inline;}
    figure {text-align: center;}
    figcaption::before {
      counter-increment: fignumber;
      content: 'Figure ' counter(fignumber) '. ';
      font-weight: bold;
    }
    .csl-entry {
      clear: left;
      margin-bottom: 1em;
    }
    .csl-left-margin {
      float: left;
      padding-right: .5em;
      text-align: right;
      width: 5em;
    }
    .csl-right-inline {
      margin: 0 .4em 0 5.5em;
      text-align: justify;
    }
    .theorem, details {
        background-color: #eee;
        border-radius: .5em;
        padding: .2em 1em;
    }
    details > p {
        margin: 0;
    }
    details > summary {
      font-weight: bold;
    }
    details {
      margin-top: 1rem;
    }
  </style>
  <script type="text/javascript">
    function change_bib_urls() {
      var div_element = document.getElementById("refs");
      var myLinks = div_element.getElementsByTagName('a');

      for (var myItem = 0; myItem < myLinks.length; myItem++) {
        var myChild = myLinks[myItem]
        myChild.innerText = "Link";
        myChild.target = "_blank";
      }
    }
  </script>
</head>
<body onload="change_bib_urls();">
<div id="header">
<h1 id="machine-learning-for-graphs-and-with-graphs">Fundamentals of Machine Learning</h2>
<!-- <center>
<img src="/courses/graph.png" width="150" />
</center> -->
<h3 id="summary">Summary</h3>
<p></p>
<p>This course aims to provide a comprehensive introduction to the fundamentals of machine learning, combining both theoretical insights and practical applications. The curriculum covers essential topics such as supervised (regression, classification, decision trees, SVMs, ensemble methods like random forests and gradient boosting, and neural networks for supervised tasks) and unsupervised learning (k-means, hierarchical clustering, dimensionality reduction methods such as PCA and t-SNE), model evaluation, optimization techniques, and common machine learning frameworks. Particular emphasis will be placed on the practical implementation of the various algorithms seen during the course (using Python). </p>
<h3 id="organization">Organization</h3>
<ul>
<li><strong>Lecturers</strong>: Titouan Vayer (Inria, ENS Lyon, LIP), Mathurin Massias (Inria, ENS Lyon, LIP), Elisa Ricietti (ENS Lyon, LIP).</li>
<li><strong>Duration</strong>: total 20 * 2 hours = 10 * 2 hours of lectures + 10 * 2 hours of practical sessions with exercises + Python sessions.</li>
</ul>
<h3 id="outline">Outline</h3>
<ol>
<li>Introduction <a href="/courses/MLCourse/course12.pdf">(slides)</a><ul>
<!-- <li>Introduction<ul> -->
<li>An introduction to machine learning (data, supervised and unsupervised learning, classification, regression)</li>
<li>Model selection and validation</li>
<li>A glimpse of statistical learning theory</li>
</ul>
</li>
<li>Linear regression <a href="/courses/MLCourse/course3.pdf">(slides)</a><ul>
<!-- <li>Introduction<ul> -->
<li>What is linear regression ?</li>
<li>Variables selection</li>
<li>Ridge/Lasso</li>
</ul>
</li>
<li>Dimension reduction <a href="/courses/MLCourse/course4.pdf">(slides)</a><ul>
<!-- <li>Introduction<ul> -->
<li>Curse of dimensionality</li>
<li>Principal components analysis</li>
<li>Non-linear dimension reduction (t-SNE)</li>
</ul>
</li>
<li>Clustering <a href="/courses/MLCourse/course5.pdf">(slides)</a><ul>
<!-- <li>Introduction<ul> -->
<li>K-means algorithm and variations (K-medoids)</li>
<li>Spectral clustering</li>
<li>Hierarchical clustering</li>
</ul>
</li>
<li>Linear classification <a href="/courses/MLCourse/course6.pdf">(slides)</a><ul>
<!-- <li>Introduction<ul> -->
<li>Linear regression</li>
<li>LDA/QDA</li>
<li>SVM and kernels <a href="/courses/GraphMLCourse/graphkernel1.pdf">(slides)</a></li>
</ul>
</li>
<li>Ensembles methods <a href="/courses/MLCourse/course7.pdf">(slides)</a><ul>
<!-- <li>Introduction<ul> -->
<li>Trees and forest</li>
<li>Boosting</li>
</ul>
</li>
<li>Neural networks and deep learning <a href="/courses/MLCourse/course8.pdf">(slides)</a><ul>
<!-- <li>Introduction<ul> -->
<li>Introduction to neural networks</li>
<li>Automatic differentiation</li>
</ul>
</li>
</ol>
</body>
</html>



