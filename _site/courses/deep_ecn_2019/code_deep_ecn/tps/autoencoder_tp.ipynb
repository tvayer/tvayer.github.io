{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work we will build simple and more complicated autoencoders on the MNIST dataset.\n",
    "\n",
    "An autoencoder is a neural network that is trained to attempt to copy its input to its output. It has two parts :\n",
    "\n",
    "\n",
    "- An encoder function $h_{\\theta_{e}} : \\mathcal{X} \\rightarrow \\mathcal{Z}$ that pushes the inputs $x$ in a smaller dimensional space.\n",
    "- A decoder function $g_{\\theta_{d}} : \\mathcal{Z} \\rightarrow \\mathcal{X}$ that reconstructs from the low dimensional space to the initial space\n",
    "\n",
    "Very generally autoencoders aim at solving  : \n",
    "\n",
    "$$\\underset{\\theta_{e},\\theta_{d}}{\\text{min}} \\ \\underset{x \\sim \\mathbb{P}_{r}}{\\mathbb{E}}[L(x,g_{\\theta_{d}},h_{\\theta_{e}})]$$\n",
    "\n",
    "<img src=\"imgs/autoencoder.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcol\n",
    "from matplotlib import cm\n",
    "def graph_colors(nx_graph):\n",
    "    #cm1 = mcol.LinearSegmentedColormap.from_list(\"MyCmapName\",[\"blue\",\"red\"])\n",
    "    #cm1 = mcol.Colormap('viridis')\n",
    "\n",
    "    cnorm = mcol.Normalize(vmin=0,vmax=9)\n",
    "    cpick = cm.ScalarMappable(norm=cnorm,cmap='Set1')\n",
    "    cpick.set_array([])\n",
    "    val_map = {}\n",
    "    for k,v in nx.get_node_attributes(nx_graph,'attr').items():\n",
    "        #print(v)\n",
    "        val_map[k]=cpick.to_rgba(v)\n",
    "    #print(val_map)\n",
    "    colors=[]\n",
    "    for node in nx_graph.nodes():\n",
    "        #print(node,val_map.get(str(node), 'black'))\n",
    "        colors.append(val_map[node])\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1. Write a function that builds a simple autoencoder \n",
    "\n",
    "The autoencoder must have a simple Dense layer with relu activation. The number of node of the dense layer is a parameter of the function.\n",
    "\n",
    "The function must return the entire autoencoder model as well as the encoder and the decoder.\n",
    "You will need the following classes:\n",
    "- [Input](https://keras.io/layers/core/)\n",
    "- [Dense](https://keras.io/layers/core/)\n",
    "- [Model](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2. Build the autoencoder with a embedding size of 32 and print the number of parameters of the model. What do they relate to ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3. Fit the autoencoder using 32 epochs with a batch size of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4. Using the history module of the autoencoder write a function that plots the learning curves with respect to the epochs on the train and test set. What can you say about these learning curves ? Give also the last loss on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5. Write a function that plots a fix number of example of the original images on the test as well as their reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbours graphs\n",
    "The goal of this part is to visualize the neighbors graph in the embedding. It corresponds the the graph of the k-nearest neighbours using the euclidean distance of points the element in the embedding\n",
    "\n",
    "The function that computes the neighbors graphs can be found here [kneighbors_graph](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.kneighbors_graph.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_nearest_neighbour_graph(encoder,x_test,y_test,ntest=100,p=3): #to explain\n",
    "    X=encoder.predict(x_test[1:ntest])\n",
    "    y=y_test[1:ntest]\n",
    "    A = kneighbors_graph(X, p, mode='connectivity', include_self=True)\n",
    "    G=nx.from_numpy_array(A.toarray())\n",
    "    nx.set_node_attributes(G,dict(zip(range(ntest),y)),'attr')\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    pos=nx.layout.kamada_kawai_layout(G)\n",
    "    nx.draw(G,pos=pos\n",
    "            ,with_labels=True\n",
    "            ,labels=nx.get_node_attributes(G,'attr')\n",
    "            ,node_color=graph_colors(G))\n",
    "    plt.tight_layout()\n",
    "    plt.title('Nearest Neighbours Graph',fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_nearest_neighbour_graph(encoder,x_test,y_test,ntest=100,p=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot a 2D MDS of the embedding space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "ntest=500\n",
    "mds=MDS(n_components=2)\n",
    "X=encoder.predict(x_test[1:ntest])\n",
    "X_dim2=mds.fit_transform(X)\n",
    "colors = ['red','green','blue','purple','darkblue','yellow','black','pink','orange','grey']\n",
    "label=y_test[1:ntest]\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(X_dim2[:,0]\n",
    "            ,X_dim2[:,1]\n",
    "            ,c=label,cmap=matplotlib.colors.ListedColormap(colors)\n",
    "           ,s=100)\n",
    "plt.colorbar()\n",
    "plt.title('MDS on embedding space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the dimension of the embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6. Rerun the previous example using an embedding dimension of 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding sparsity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 7.  Add sparisity over the weights\n",
    "\n",
    "In this part we will add sparisity over the weights on the embedding layer. Write a function that build such a autoencoder (using a l1 regularization with a configurable regularization parameter and using the same autoencoder architecture that before)\n",
    "\n",
    "You will use the [regularizers](https://keras.io/regularizers/) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 8. Use the following deep autoencoder to rerun the previous example. What can you say about the quality of the autoencoding ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_deep_autoencoder(encoding_dim=32):\n",
    "    \n",
    "\n",
    "    input_img = Input(shape=(784,))\n",
    "    encoded = Dense(128, activation='relu')(input_img)\n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    encoded = Dense(encoding_dim, activation='relu', name=\"embedding_layer\")(encoded)\n",
    "\n",
    "    encoder=Model(input_img, encoded)\n",
    "\n",
    "    \n",
    "    decoded = Dense(64, activation='relu')(encoded)\n",
    "    decoded = Dense(128, activation='relu')(decoded)\n",
    "    decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    \n",
    "\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    \n",
    "    return autoencoder,encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 8. Use the following convolutional autoencoder to rerun the previous example. What can you say about the quality of the autoencoding ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def build_conv_autoencoder():\n",
    "    input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    encoder= Model(input_img, encoded)\n",
    "\n",
    "    # at this point the representation is (7, 7, 32)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "    \n",
    "    return autoencoder,encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will add some noise to the original data to see how the auto-encoding process denoises our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 9. Denoise using the convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
