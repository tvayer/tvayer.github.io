{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a GAN we want to construct a distribution $\\mathbb{P}_{g}$, called a generative distribution, which mimics the real distribution $\\mathbb{P}_{r}$. \n",
    "\n",
    "For that we use a neural network $G=g_{\\theta}$, a noise $p(z)$ such that $x'=g_{\\theta}(z), z \\sim p(z)$ and a discriminator D:\n",
    "\n",
    "$$\\underset{D}{\\text{max}} \\ \\underset{g_{\\theta}}{\\text{min}} \\  L(D,g_{\\theta}) = \\underset{x \\sim \\mathbb{P}_{r}}{\\mathbb{E}}[\\log(D(x))]+ \\underset{z \\sim p(z)}{\\mathbb{E}}[\\log(1-D(g_{\\theta}(z)))]$$\n",
    "\n",
    "<img src=\"imgs/gan.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Rescale -1 to 1\n",
    "X_train = x_train / 127.5 - 1.\n",
    "X_train = np.expand_dims(x_train, axis=3)\n",
    "X_train.shape\n",
    "x_test.shape\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "plt.imshow(X_train[46].reshape(28,28))\n",
    "plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1. Create a generator model\n",
    "The generator has the following layers :\n",
    "    - A dense layer of width 256 and take as input the dimension of the latent space (this is a paremeter that must be configurable\n",
    "    - A LeakyRelu activation with parameter alpha=0.2 : what does it correspond to ?\n",
    "    - We use batch normalization of momentum 0.8 : what does it correspond to ?\n",
    "    \n",
    "    - A second dense layer of width 512\n",
    "    - We use same LeakyRelu and batch normalization for this layer\n",
    "    \n",
    "    - A third Dense Layer of width 1024 with same batch normalization and LeakyRelu activation\n",
    "    \n",
    "    - A last dense layer with width equal to the shape of the output image flattened\n",
    "    - The activation is tanh : what does is correspond to ?\n",
    "    \n",
    "    The function must take as input a vector of dimension the dimension of the latent space and representing the noise and return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_generator(img_shape,latent_dim=100):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    \n",
    "    model.add(Reshape(img_shape))\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen=build_generator(img_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2. Build the discriminator\n",
    "The discriminator has the following layers :\n",
    "    - A Dense layer of width 512 with LeakyRelu activation with parameter alpha=0.2\n",
    "    - A second Dense layer with LeakyRelu activation with parameter alpha=0.2\n",
    "    - A last Dense layer for the binary classification \n",
    "    \n",
    "    The model must take as input an image and output the the classification result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3. Build the two neural networks with the MNIST configuration and print their properties. We will use 100 as the dimension of the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Compile the model\n",
    "\n",
    "The optimizer chosen is 'Adam' with parameters 0.0002 and 0.5 : what does it correspond to ?\n",
    "\n",
    "First compile the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compile the generator it is more tricky : (live explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The generator takes noise as input and generates imgs\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "validity = discriminator(img)\n",
    "\n",
    "# The combined model  (stacked generator and discriminator)\n",
    "# Trains the generator to fool the discriminator\n",
    "combined = Model(z, validity)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5. Write a function that samples 25 images from a normal noise $\\mathcal{N}(0,I_{d})$ with d configurable. It should be configurable wether we save or plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Train the model using batch_size of 32 and 10000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Sample 25 generated images and plot the loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
